{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "__all__ = ['iresnet18', 'iresnet34', 'iresnet50', 'iresnet100', 'iresnet200']\n",
    "using_ckpt = False\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=dilation,\n",
    "                     groups=groups,\n",
    "                     bias=False,\n",
    "                     dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=1,\n",
    "                     stride=stride,\n",
    "                     bias=False)\n",
    "\n",
    "\n",
    "class IBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 groups=1, base_width=64, dilation=1):\n",
    "        super(IBasicBlock, self).__init__()\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes, eps=1e-05,)\n",
    "        self.conv1 = conv3x3(inplanes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, eps=1e-05,)\n",
    "        self.prelu = nn.PReLU(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn3 = nn.BatchNorm2d(planes, eps=1e-05,)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward_impl(self, x):\n",
    "        identity = x\n",
    "        out = self.bn1(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.prelu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return out        \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and using_ckpt:\n",
    "            return checkpoint(self.forward_impl, x)\n",
    "        else:\n",
    "            return self.forward_impl(x)\n",
    "\n",
    "\n",
    "class IResNet(nn.Module):\n",
    "    fc_scale = 7 * 7\n",
    "    def __init__(self,\n",
    "                 block, layers, dropout=0, num_features=512, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None, fp16=False):\n",
    "        super(IResNet, self).__init__()\n",
    "        self.extra_gflops = 0.0\n",
    "        self.fp16 = fp16\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes, eps=1e-05)\n",
    "        self.prelu = nn.PReLU(self.inplanes)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block,\n",
    "                                       128,\n",
    "                                       layers[1],\n",
    "                                       stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block,\n",
    "                                       256,\n",
    "                                       layers[2],\n",
    "                                       stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block,\n",
    "                                       512,\n",
    "                                       layers[3],\n",
    "                                       stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.bn2 = nn.BatchNorm2d(512 * block.expansion, eps=1e-05,)\n",
    "        self.dropout = nn.Dropout(p=dropout, inplace=True)\n",
    "        self.fc = nn.Linear(512 * block.expansion * self.fc_scale, num_features)\n",
    "        self.features = nn.BatchNorm1d(num_features, eps=1e-05)\n",
    "        nn.init.constant_(self.features.weight, 1.0)\n",
    "        self.features.weight.requires_grad = False\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, 0, 0.1)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, IBasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion, eps=1e-05, ),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                  self.base_width, previous_dilation))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(self.inplanes,\n",
    "                      planes,\n",
    "                      groups=self.groups,\n",
    "                      base_width=self.base_width,\n",
    "                      dilation=self.dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.cuda.amp.autocast(self.fp16):\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.prelu(x)\n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.layer3(x)\n",
    "            x = self.layer4(x)\n",
    "            x = self.bn2(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc(x.float() if self.fp16 else x)\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def _iresnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = IResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        raise ValueError()\n",
    "    return model\n",
    "\n",
    "\n",
    "def iresnet18(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet18', IBasicBlock, [2, 2, 2, 2], pretrained,\n",
    "                    progress, **kwargs)\n",
    "\n",
    "\n",
    "def iresnet34(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet34', IBasicBlock, [3, 4, 6, 3], pretrained,\n",
    "                    progress, **kwargs)\n",
    "\n",
    "\n",
    "def iresnet50(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet50', IBasicBlock, [3, 4, 14, 3], pretrained,\n",
    "                    progress, **kwargs)\n",
    "\n",
    "\n",
    "def iresnet100(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet100', IBasicBlock, [3, 13, 30, 3], pretrained,\n",
    "                    progress, **kwargs)\n",
    "\n",
    "\n",
    "def iresnet200(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet200', IBasicBlock, [6, 26, 60, 6], pretrained,\n",
    "                    progress, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "model = iresnet18(fp16=True)\n",
    "model.load_state_dict(torch.load(\"./backbone_16.pth\",map_location=torch.device('mps')))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    " # Export the model\n",
    "\n",
    "def get_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (112, 112))\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = torch.from_numpy(img).unsqueeze(0).float()\n",
    "    img.div_(255).sub_(0.5).div_(0.5)\n",
    "    return img\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(model,img):\n",
    "    img = get_img(img)\n",
    "    feat = model(img).numpy()\n",
    "    print(feat.shape)\n",
    "    return feat.flatten()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 24.0M\n",
      "Model Size: 96.1M\n"
     ]
    }
   ],
   "source": [
    "#get model params and size\n",
    "params = sum([np.prod(p.size()) for p in model.parameters()])\n",
    "print(\"Number of Parameters: %.1fM\"%(params/1e6))\n",
    "print(\"Model Size: %.1fM\"%(params*4/1e6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512)\n",
      "(1, 512)\n",
      "(1, 512)\n",
      "cosine similarity between ema and ema2: 0.8636\n",
      "cosine similarity between ema and john: 0.1040\n",
      "cosine similarity between ema2 and john: 0.1437\n",
      "cosine similarity between ema and ema: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carbs/miniforge3/envs/ai/lib/python3.11/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    f1 = inference(model, \"./ema.png\")\n",
    "    f2 = inference(model, \"./ema2.png\")\n",
    "    f3 = inference(model, \"./john.png\")\n",
    "   \n",
    "\n",
    "    #compoute cosine similarity\n",
    "    from scipy.spatial.distance import cosine\n",
    "    print(\"cosine similarity between ema and ema2: %.4f\"%(1-cosine(f1,f2)))\n",
    "    print(\"cosine similarity between ema and john: %.4f\"%(1-cosine(f1,f3)))\n",
    "    print(\"cosine similarity between ema2 and john: %.4f\"%(1-cosine(f2,f3)))\n",
    "    print(\"cosine similarity between ema and ema: %.4f\"%(1-cosine(f1,f1)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import ezkl\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# uncomment for more descriptive logging \n",
    "FORMAT = '%(levelname)s %(name)s %(asctime)-15s %(filename)s:%(lineno)d %(message)s'\n",
    "logging.basicConfig(format=FORMAT)\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carbs/miniforge3/envs/ai/lib/python3.11/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = get_img(\"./ema.png\")\n",
    "\n",
    "torch.onnx.export(model,               # model being run\n",
    "                      x,                   # model input (or a tuple for multiple inputs)\n",
    "                      \"network.onnx\",            # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=10,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names = ['input'],   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                    'output' : {0 : 'batch_size'}})\n",
    "\n",
    "data_array = ((x).to(\"cpu\").detach().numpy()).reshape([-1]).tolist()\n",
    "\n",
    "data = dict(input_data = [data_array])\n",
    "\n",
    "    # Serialize data into file:\n",
    "json.dump( data, open(\"input.json\", 'w' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "\n",
    "model_path = os.path.join('network.onnx')\n",
    "compiled_model_path = os.path.join('network.compiled')\n",
    "pk_path = os.path.join('test.pk')\n",
    "vk_path = os.path.join('test.vk')\n",
    "settings_path = os.path.join('settings.json')\n",
    "srs_path = os.path.join('kzg.srs')\n",
    "data_path = os.path.join('input.json')\n",
    "\n",
    "run_args = ezkl.PyRunArgs()\n",
    "run_args.input_visibility = \"private\"\n",
    "run_args.param_visibility = \"public\"\n",
    "run_args.output_visibility = \"public\"\n",
    "run_args.variables = [(\"batch_size\", 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO ezkl.graph.model 2023-09-16 22:13:36,062 model.rs:708 set batch_size to 1\n",
      "INFO ezkl.graph.model 2023-09-16 22:13:57,972 model.rs:416 model has 1 instances\n"
     ]
    }
   ],
   "source": [
    "!RUST_LOG=trace\n",
    "# TODO: Dictionary outputs\n",
    "res = ezkl.gen_settings(model_path, settings_path, py_run_args=run_args)\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cal_data = {\n",
    "    \"input_data\": [data_array],\n",
    "}\n",
    "\n",
    "print(cal_data)\n",
    "\n",
    "\n",
    "\n",
    "# cal_path = os.path.join('val_data.json')\n",
    "# # save as json file\n",
    "# with open(cal_path, \"w\") as f:\n",
    "#     json.dump(cal_data, f)\n",
    "\n",
    "# res = await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ezkl.compile_model(model_path, compiled_model_path, settings_path)\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ezkl.get_srs(srs_path, settings_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export RUST_BACKTRACE=1\n",
    "\n",
    "witness_path = \"witness.json\"\n",
    "\n",
    "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path, settings_path = settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ezkl.mock(witness_path, compiled_model_path, settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE WE SETUP THE CIRCUIT PARAMS\n",
    "# WE GOT KEYS\n",
    "# WE GOT CIRCUIT PARAMETERS\n",
    "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        srs_path,\n",
    "        settings_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "assert os.path.isfile(settings_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
